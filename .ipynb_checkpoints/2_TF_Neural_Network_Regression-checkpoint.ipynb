{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ad22d1-001d-44a6-ab36-eb8dce579fb4",
   "metadata": {},
   "source": [
    "# Neural Network Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950849c7-2560-472f-b70d-fdaf22567aac",
   "metadata": {},
   "source": [
    "Regression problem - predicting a numerical variable based on some other combinations of variables, even shorter... predicting a number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4307e048-1bf7-4c8c-ac2a-a3ed8b5cfaaf",
   "metadata": {},
   "source": [
    "### Create data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f8480a2-d2e3-4dc1-8ddc-f7f8bd727239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "953d6c76-7332-4817-aac1-9753b592ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features\n",
    "X = np.array([-7., -4., -1., 2., 5., 8., 11., 14.]) \n",
    "\n",
    "# Create labels\n",
    "Y = np.array([3., 6., 9., 12., 15., 18., 21., 24.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee5c67e5-8b18-4a4a-8fa9-dd00e2b3e863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x30b4f1ee0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGiCAYAAAA8xWYrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHfpJREFUeJzt3XFslPd9+PHP2bRn0plbDTV3XsC1IlLJdZaNppBEbRIqgcwfXhPWKWnEBNJWZZREpSjKlmWV8dqCEmlR/mBDWidlqVjW/rNlRYlImTKgU8JgELQCVUVUZ2GaPa9xYhsWOwp+fn9Q/MOxgRjOvq/Pr5d0Uu55Hvs+0enkN89z971clmVZAAAkoqbSAwAAXEqcAABJEScAQFLECQCQFHECACRFnAAASREnAEBSxAkAkBRxAgAkRZwAAEmZUpzs2LEjPv/5z0d9fX00NjbGvffeGz//+c/HHbNx48bI5XLjbrfffntZhwYAqteU4uTAgQOxefPmOHToUOzbty8++OCDWLNmTZw7d27cce3t7dHT0zN2e+mll8o6NABQveZN5eC9e/eOu//ss89GY2NjHD16NO66666x7fl8PorFYnkmBADmlCnFyYcNDAxERERDQ8O47fv374/Gxsb49V//9bj77rvju9/9bjQ2Nk76O0ZGRmJkZGTs/ujoaPT398fChQsjl8tdz3gAwAzJsiyGhoaiqakpamqu7y2tuSzLsmsd4stf/nK888478ZOf/GRs+w9/+MP4tV/7tWhubo7u7u741re+FR988EEcPXo08vn8hN+zbdu26Orquvb/AwAgGWfOnIkbb7zxun7HNcfJ5s2b48UXX4x//dd/veIQPT090dzcHD/4wQ9i3bp1E/Z/+MzJwMBALF26NM6cORMLFiy4ltEAgBk2ODgYS5YsiXfffTcKhcJ1/a5ruqzzyCOPxI9+9KM4ePDgVeuoVCpFc3NznD59etL9+Xx+0jMqCxYsECcAMMuU4y0ZU4qTLMvikUceiX/8x3+M/fv3R0tLy1V/5u23344zZ85EqVS65iEBgLljSu9Y2bx5c+zevTuef/75qK+vj97e3ujt7Y333nsvIiLOnj0bjz76aLz22mvx5ptvxv79+6OjoyMWLVoU991337T8DwAA1WVK7zm53KmaZ599NjZu3Bjvvfde3HvvvfH666/Hu+++G6VSKVatWhXf/va3Y8mSJR/pMQYHB6NQKMTAwIDLOgAwS5Tz7/eUL+tcyfz58+Pll1++roEAgLnNd+sAAEkRJwBAUsQJAJAUcQIAJOW6vlsHAJg9zo9mcbi7P/qGhqOxvi5WtDREbU1632MnTgBgDth7oie69pyKnoHhsW2lQl10drRGe1taC6W6rAMAVW7viZ7YtPvYuDCJiOgdGI5Nu4/F3hM9FZpscuIEAKrY+dEsuvacislWKru4rWvPqTg/ek3fAzwtxAkAVLHD3f0TzphcKouInoHhONzdP3NDXYU4AYAq1jd0+TC5luNmgjgBgCrWWF9X1uNmgjgBgCq2oqUhSoW6uNwHhnNx4VM7K1oaZnKsKxInAFDFamty0dnRGhExIVAu3u/saE1qvRNxAgBVrr2tFLvWL49iYfylm2KhLnatX57cOicWYQOAOaC9rRSrW4tWiAUA0lFbk4s7blpY6TGuymUdACAp4gQASIo4AQCSIk4AgKSIEwAgKeIEAEiKOAEAkiJOAICkiBMAICniBABIijgBAJIiTgCApIgTACAp4gQASIo4AQCSIk4AgKSIEwAgKeIEAEiKOAEAkiJOAICkiBMAICniBABIijgBAJIiTgCApIgTACAp4gQASIo4AQCSIk4AgKSIEwAgKeIEAEiKOAEAkiJOAICkiBMAICniBABIijgBAJIiTgCApMyr9AAAMFPOj2ZxuLs/+oaGo7G+Lla0NERtTa7SY/Eh4gSAOWHviZ7o2nMqegaGx7aVCnXR2dEa7W2lCk7Gh7msA0DV23uiJzbtPjYuTCIiegeGY9PuY7H3RE+FJmMy4gSAqnZ+NIuuPacim2TfxW1de07F+dHJjqASxAkAVe1wd/+EMyaXyiKiZ2A4Dnf3z9xQXJE4AaCq9Q1dPkyu5TimnzgBoKo11teV9TimnzgBoKqtaGmIUqEuLveB4Vxc+NTOipaGmRyLKxAnAFS12ppcdHa0RkRMCJSL9zs7Wq13khBxAkDVa28rxa71y6NYGH/pplioi13rl1vnJDEWYQNgTmhvK8Xq1qIVYmcBcQLAnFFbk4s7blpY6TG4Cpd1AICkiBMAICniBABIijgBAJIiTgCApEwpTnbs2BGf//zno76+PhobG+Pee++Nn//85+OOybIstm3bFk1NTTF//vy455574uTJk2UdGgCoXlOKkwMHDsTmzZvj0KFDsW/fvvjggw9izZo1ce7cubFjnnrqqXj66adj586dceTIkSgWi7F69eoYGhoq+/AAQPXJZVmWXesP/+///m80NjbGgQMH4q677oosy6KpqSm2bNkSf/zHfxwRESMjI7F48eJ48skn46GHHrrq7xwcHIxCoRADAwOxYMGCax0NAJhB5fz7fV3vORkYGIiIiIaGC1+W1N3dHb29vbFmzZqxY/L5fNx9993x6quvTvo7RkZGYnBwcNwNAJi7rjlOsiyLrVu3xhe+8IVoa2uLiIje3t6IiFi8ePG4YxcvXjy278N27NgRhUJh7LZkyZJrHQkAqALXHCcPP/xw/Md//Ef8/d///YR9udz47ynIsmzCtosef/zxGBgYGLudOXPmWkcCAKrANX23ziOPPBI/+tGP4uDBg3HjjTeObS8WixFx4QxKqfT/v+Gxr69vwtmUi/L5fOTz+WsZAwCoQlM6c5JlWTz88MPxD//wD/HKK69ES0vLuP0tLS1RLBZj3759Y9vef//9OHDgQNx5553lmRgAqGpTOnOyefPmeP755+Of/umfor6+fux9JIVCIebPnx+5XC62bNkS27dvj2XLlsWyZcti+/btccMNN8SDDz44Lf8DAEB1mVKc7Nq1KyIi7rnnnnHbn3322di4cWNERDz22GPx3nvvxde//vV45513YuXKlfHjH/846uvryzIwAFDdrmudk+lgnRMAmH2SWecEAKDcxAkAkBRxAgAkRZwAAEkRJwBAUsQJAJAUcQIAJEWcAABJEScAQFLECQCQFHECACRFnAAASREnAEBSxAkAkBRxAgAkRZwAAEkRJwBAUsQJAJAUcQIAJEWcAABJmVfpAQCYGedHszjc3R99Q8PRWF8XK1oaorYmV+mxYAJxAjAH7D3RE117TkXPwPDYtlKhLjo7WqO9rVTByWAil3UAqtzeEz2xafexcWESEdE7MBybdh+LvSd6KjQZTE6cAFSx86NZdO05Fdkk+y5u69pzKs6PTnYEVIY4Aahih7v7J5wxuVQWET0Dw3G4u3/mhoKrECcAVaxv6PJhci3HwUwQJwBVrLG+rqzHwUwQJwBVbEVLQ5QKdXG5Dwzn4sKndla0NMzkWHBF4gSgitXW5KKzozUiYkKgXLzf2dFqvROSIk4Aqlx7Wyl2rV8excL4SzfFQl3sWr/cOickxyJsAHNAe1spVrcWrRDLrCBOAOaI2ppc3HHTwkqPAVflsg4AkBRxAgAkRZwAAEkRJwBAUsQJAJAUcQIAJEWcAABJEScAQFLECQCQFHECACRFnAAASREnAEBSxAkAkBRxAgAkRZwAAEkRJwBAUsQJAJAUcQIAJEWcAABJEScAQFLECQCQFHECACRFnAAASREnAEBSxAkAkBRxAgAkRZwAAEkRJwBAUsQJAJAUcQIAJEWcAABJEScAQFLECQCQFHECACRFnAAASREnAEBS5lV6AICZcn40i8Pd/dE3NByN9XWxoqUhamtylR4L+JApnzk5ePBgdHR0RFNTU+RyuXjhhRfG7d+4cWPkcrlxt9tvv71c8wJck70neuILT74SX/3eofjGD47HV793KL7w5Cux90RPpUcDPmTKcXLu3Lm49dZbY+fOnZc9pr29PXp6esZuL7300nUNCXA99p7oiU27j0XPwPC47b0Dw7Fp9zGBAomZ8mWdtWvXxtq1a694TD6fj2KxeM1DAZTL+dEsuvacimySfVlE5CKia8+pWN1adIkHEjEtb4jdv39/NDY2xs033xxf+9rXoq+v77LHjoyMxODg4LgbQLkc7u6fcMbkUllE9AwMx+Hu/pkbCriissfJ2rVr4+/+7u/ilVdeib/4i7+II0eOxJe+9KUYGRmZ9PgdO3ZEoVAYuy1ZsqTcIwFzWN/Q5cPkWo4Dpl/ZP61z//33j/13W1tb3HbbbdHc3BwvvvhirFu3bsLxjz/+eGzdunXs/uDgoEAByqaxvq6sxwHTb9o/SlwqlaK5uTlOnz496f58Ph/5fH66xwDmqBUtDVEq1EXvwPCk7zvJRUSxcOFjxUAapn0RtrfffjvOnDkTpVJpuh8KYILamlx0drRGxIUQudTF+50drd4MCwmZcpycPXs2jh8/HsePH4+IiO7u7jh+/Hi89dZbcfbs2Xj00UfjtddeizfffDP2798fHR0dsWjRorjvvvvKPTvAR9LeVopd65dHsTD+0k2xUBe71i+P9jb/eIKU5LIsm+xM52Xt378/Vq1aNWH7hg0bYteuXXHvvffG66+/Hu+++26USqVYtWpVfPvb3/7I7yMZHByMQqEQAwMDsWDBgqmMBnBFVoiF6VPOv99TjpPpJk4AYPYp599vX/wHACRFnAAASREnAEBSxAkAkBRxAgAkRZwAAEkRJwBAUsQJAJAUcQIAJEWcAABJEScAQFLECQCQFHECACRFnAAASREnAEBSxAkAkBRxAgAkRZwAAEkRJwBAUsQJAJAUcQIAJEWcAABJEScAQFLECQCQFHECACRFnAAASREnAEBSxAkAkBRxAgAkRZwAAEkRJwBAUsQJAJAUcQIAJEWcAABJEScAQFLECQCQlHmVHgCYGedHszjc3R99Q8PRWF8XK1oaorYmV+mxACYQJzAH7D3RE117TkXPwPDYtlKhLjo7WqO9rVTByQAmclkHqtzeEz2xafexcWESEdE7MBybdh+LvSd6KjQZwOTECVSx86NZdO05Fdkk+y5u69pzKs6PTnYEQGWIE6hih7v7J5wxuVQWET0Dw3G4u3/mhgK4CnECVaxv6PJhci3HAcwEcQJVrLG+rqzHAcwEcQJVbEVLQ5QKdXG5Dwzn4sKndla0NMzkWABXJE6gitXW5KKzozUiYkKgXLzf2dFqvRMgKeIEqlx7Wyl2rV8excL4SzfFQl3sWr/cOidAcizCBnNAe1spVrcWrRALzAriBOaI2ppc3HHTwkqPAXBVLusAAEkRJwBAUsQJAJAUcQIAJEWcAABJEScAQFLECQCQFHECACRFnAAASREnAEBSxAkAkBRxAgAkRZwAAEkRJwBAUsQJAJAUcQIAJEWcAABJEScAQFLECQCQFHECACRFnAAASZlynBw8eDA6OjqiqakpcrlcvPDCC+P2Z1kW27Zti6amppg/f37cc889cfLkyXLNCwBUuSnHyblz5+LWW2+NnTt3Trr/qaeeiqeffjp27twZR44ciWKxGKtXr46hoaHrHhYAqH7zpvoDa9eujbVr1066L8uyeOaZZ+KJJ56IdevWRUTEc889F4sXL47nn38+HnrooeubFgCoemV9z0l3d3f09vbGmjVrxrbl8/m4++6749VXX530Z0ZGRmJwcHDcDQCYu8oaJ729vRERsXjx4nHbFy9ePLbvw3bs2BGFQmHstmTJknKOBADMMtPyaZ1cLjfufpZlE7Zd9Pjjj8fAwMDY7cyZM9MxEgAwS0z5PSdXUiwWI+LCGZRSqTS2va+vb8LZlIvy+Xzk8/lyjgEAzGJlPXPS0tISxWIx9u3bN7bt/fffjwMHDsSdd95ZzocCAKrUlM+cnD17Nt54442x+93d3XH8+PFoaGiIpUuXxpYtW2L79u2xbNmyWLZsWWzfvj1uuOGGePDBB8s6OABQnaYcJ//+7/8eq1atGru/devWiIjYsGFD/O3f/m089thj8d5778XXv/71eOedd2LlypXx4x//OOrr68s3NQBQtXJZlmWVHuJSg4ODUSgUYmBgIBYsWFDpcQCAj6Ccf799tw4AkBRxAgAkRZwAAEkRJwBAUsq6CBuk7PxoFoe7+6NvaDga6+tiRUtD1NZMvnIxAJUjTpgT9p7oia49p6JnYHhsW6lQF50drdHeVrrCTwIw01zWoertPdETm3YfGxcmERG9A8Oxafex2Huip0KTATAZcUJVOz+aRdeeUzHZYj4Xt3XtORXnR5Na7gdgThMnVLXD3f0TzphcKouInoHhONzdP3NDAXBF4oSq1jd0+TC5luMAmH7ihKrWWF9X1uMAmH7ihKq2oqUhSoW6uNwHhnNx4VM7K1oaZnIsAK5AnFDVamty0dnRGhExIVAu3u/saLXeCUBCxAlVr72tFLvWL49iYfylm2KhLnatX26dE4DEWISNOaG9rRSrW4tWiAWYBcQJc0ZtTS7uuGlhpccA4Cpc1gEAkiJOAICkiBMAICniBABIijgBAJIiTgCApIgTACAp4gQASIo4AQCSIk4AgKSIEwAgKeIEAEiKOAEAkiJOAICkiBMAICniBABIijgBAJIiTgCApIgTACAp4gQASIo4AQCSIk4AgKSIEwAgKeIEAEiKOAEAkiJOAICkiBMAICniBABIijgBAJIiTgCApIgTACAp4gQASIo4AQCSIk4AgKSIEwAgKeIEAEjKvEoPwMw4P5rF4e7+6Bsajsb6uljR0hC1NblKjwUAE4iTOWDviZ7o2nMqegaGx7aVCnXR2dEa7W2lCk4GABO5rFPl9p7oiU27j40Lk4iI3oHh2LT7WOw90VOhyQBgcuKkip0fzaJrz6nIJtl3cVvXnlNxfnSyIwCgMsRJFTvc3T/hjMmlsojoGRiOw939MzcUAFyFOKlifUOXD5NrOQ4AZoI4qWKN9XVlPQ4AZoI4qWIrWhqiVKiLy31gOBcXPrWzoqVhJscCgCsSJ1WstiYXnR2tERETAuXi/c6OVuudAJAUcVLl2ttKsWv98igWxl+6KRbqYtf65dY5ASA5FmGbA9rbSrG6tWiFWABmBXEyR9TW5OKOmxZWegwAuCqXdQCApIgTACAp4gQASIo4AQCSIk4AgKSUPU62bdsWuVxu3K1YLJb7YQCAKjUtHyX+7Gc/G//8z/88dr+2tnY6HgYAqELTEifz5s1ztgQAuCbT8p6T06dPR1NTU7S0tMQDDzwQv/jFLy577MjISAwODo67AQBzV9njZOXKlfH9738/Xn755fje974Xvb29ceedd8bbb7896fE7duyIQqEwdluyZEm5RwIAZpFclmXZdD7AuXPn4qabborHHnsstm7dOmH/yMhIjIyMjN0fHByMJUuWxMDAQCxYsGA6RwMAymRwcDAKhUJZ/n5P+3frfOITn4hbbrklTp8+Pen+fD4f+Xx+uscAAGaJaV/nZGRkJH72s59FqVSa7ocCAKpA2ePk0UcfjQMHDkR3d3f827/9W3zlK1+JwcHB2LBhQ7kfCgCoQmW/rPNf//Vf8dWvfjV++ctfxqc+9am4/fbb49ChQ9Hc3FzuhwIAqlDZ4+QHP/hBuX8lADCH+G4dACAp4gQASIo4AQCSIk4AgKSIEwAgKeIEAEiKOAEAkiJOAICkiBMAICniBABIijgBAJIiTgCApIgTACAp4gQASIo4AQCSIk4AgKSIEwAgKeIEAEiKOAEAkiJOAICkzKv0ADPl/GgWh7v7o29oOBrr62JFS0PU1uQqPRYA8CFzIk72nuiJrj2nomdgeGxbqVAXnR2t0d5WquBkAMCHVf1lnb0nemLT7mPjwiQiondgODbtPhZ7T/RUaDIAYDJVHSfnR7Po2nMqskn2XdzWtedUnB+d7AgAoBKqOk4Od/dPOGNyqSwiegaG43B3/8wNBQBcUVXHSd/Q5cPkWo4DAKZfVcdJY31dWY8DAKZfVcfJipaGKBXq4nIfGM7FhU/trGhpmMmxAIArqOo4qa3JRWdHa0TEhEC5eL+zo9V6JwCQkKqOk4iI9rZS7Fq/PIqF8ZduioW62LV+uXVOACAxc2IRtva2UqxuLVohFgBmgTkRJxEXLvHccdPCSo8BAFxF1V/WAQBmF3ECACRFnAAASREnAEBSxAkAkBRxAgAkRZwAAEkRJwBAUsQJAJCU5FaIzbIsIiIGBwcrPAkA8FFd/Lt98e/49UguToaGhiIiYsmSJRWeBACYqqGhoSgUCtf1O3JZORKnjEZHR+O///u/o76+PnK5ufvFfIODg7FkyZI4c+ZMLFiwoNLjcAWeq9nF8zV7eK5mj4vP1alTp+Izn/lM1NRc37tGkjtzUlNTEzfeeGOlx0jGggULvChnCc/V7OL5mj08V7PHb/zGb1x3mER4QywAkBhxAgAkRZwkKp/PR2dnZ+Tz+UqPwlV4rmYXz9fs4bmaPcr9XCX3hlgAYG5z5gQASIo4AQCSIk4AgKSIEwAgKeJkFvj0pz8duVxu3O1P/uRPKj0Wv/JXf/VX0dLSEnV1dfG5z30ufvKTn1R6JD5k27ZtE15DxWKx0mPxKwcPHoyOjo5oamqKXC4XL7zwwrj9WZbFtm3boqmpKebPnx/33HNPnDx5sjLDznFXe642btw44bV2++23T/lxxMks8ed//ufR09MzdvuzP/uzSo9ERPzwhz+MLVu2xBNPPBGvv/56fPGLX4y1a9fGW2+9VenR+JDPfvaz415DP/3pTys9Er9y7ty5uPXWW2Pnzp2T7n/qqafi6aefjp07d8aRI0eiWCzG6tWrx76LjZlztecqIqK9vX3ca+2ll16a8uMkt3w9k6uvr/cvvQQ9/fTT8Qd/8Afxh3/4hxER8cwzz8TLL78cu3btih07dlR4Oi41b948r6FErV27NtauXTvpvizL4plnnoknnngi1q1bFxERzz33XCxevDief/75eOihh2Zy1DnvSs/VRfl8/rpfa86czBJPPvlkLFy4MH7rt34rvvvd78b7779f6ZHmvPfffz+OHj0aa9asGbd9zZo18eqrr1ZoKi7n9OnT0dTUFC0tLfHAAw/EL37xi0qPxEfQ3d0dvb29415n+Xw+7r77bq+zRO3fvz8aGxvj5ptvjq997WvR19c35d/hzMks8I1vfCOWL18en/zkJ+Pw4cPx+OOPR3d3d/zN3/xNpUeb0375y1/G+fPnY/HixeO2L168OHp7eys0FZNZuXJlfP/734+bb745/ud//ie+853vxJ133hknT56MhQsXVno8ruDia2my19l//ud/VmIkrmDt2rXxe7/3e9Hc3Bzd3d3xrW99K770pS/F0aNHp7R6rDipkG3btkVXV9cVjzly5Ejcdttt8c1vfnNs22/+5m/GJz/5yfjKV74ydjaFysrlcuPuZ1k2YRuVdelp6FtuuSXuuOOOuOmmm+K5556LrVu3VnAyPiqvs9nh/vvvH/vvtra2uO2226K5uTlefPHFsctyH4U4qZCHH344HnjggSse8+lPf3rS7Rff+fzGG2+IkwpatGhR1NbWTjhL0tfXN+FfeaTlE5/4RNxyyy1x+vTpSo/CVVx870Jvb2+USqWx7V5ns0OpVIrm5uYpv9bESYUsWrQoFi1adE0/+/rrr0dEjHuhMvM+/vGPx+c+97nYt29f3HfffWPb9+3bF1/+8pcrOBlXMzIyEj/72c/ii1/8YqVH4SpaWlqiWCzGvn374rd/+7cj4sL7vQ4cOBBPPvlkhafjat5+++04c+bMlP9eiZPEvfbaa3Ho0KFYtWpVFAqFOHLkSHzzm9+M3/md34mlS5dWerw5b+vWrfH7v//7cdttt8Udd9wRf/3Xfx1vvfVW/NEf/VGlR+MSjz76aHR0dMTSpUujr68vvvOd78Tg4GBs2LCh0qMREWfPno033nhj7H53d3ccP348GhoaYunSpbFly5bYvn17LFu2LJYtWxbbt2+PG264IR588MEKTj03Xem5amhoiG3btsXv/u7vRqlUijfffDP+9E//NBYtWjTuH3AfSUbSjh49mq1cuTIrFApZXV1d9pnPfCbr7OzMzp07V+nR+JW//Mu/zJqbm7OPf/zj2fLly7MDBw5UeiQ+5P77789KpVL2sY99LGtqasrWrVuXnTx5stJj8Sv/8i//kkXEhNuGDRuyLMuy0dHRrLOzMysWi1k+n8/uuuuu7Kc//Wllh56jrvRc/d///V+2Zs2a7FOf+lT2sY99LFu6dGm2YcOG7K233pry4+SyLMvKklMAAGVgnRMAICniBABIijgBAJIiTgCApIgTACAp4gQASIo4AQCSIk4AgKSIEwAgKeIEAEiKOAEAkiJOAICk/D/JMLfhL69rgwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize it\n",
    "plt.scatter(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f22d381-8c44-4a36-a0b5-e70b78f7f7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y == X + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "29af3cc8-8dd3-481a-8c1d-fdcbb8b92e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a demo tensor for our housing price prediction\n",
    "house_info = tf.constant(['bedroom', 'bathroom', 'garage'])\n",
    "house_price = tf.constant([939700])\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a8616730-4dbe-4e6c-875e-c4952fb9360b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8,), (8,))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X.shape\n",
    "output_shape = Y.shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "074624f6-0340-426b-b233-7f47ec5960d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our numpy arrays into tensors\n",
    "X = tf.cast(tf.constant(X), dtype = tf.float32)\n",
    "Y = tf.cast(tf.constant(Y), dtype = tf.float32)\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1388cc83-68a1-4a4d-80d7-c78923dc6b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = Y[0].shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ae7a7-bf85-418b-a9ea-5806f4776695",
   "metadata": {},
   "source": [
    "### Steps in modelling with tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f945e2-8aaa-4e6c-b19c-4a89ad3c54b7",
   "metadata": {},
   "source": [
    "1. Creating the model - define input, output and hidden layers.\n",
    "2. Compiling the model - define the loss function (the function which tells out model how wrong it is), and the optimizer (tells our model how to improve the patterns it is learning), and evaluation metrics (what we can use to improve the performance of our model).\n",
    "3. Fitting a model - letting the model try to find patterns between X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f668153a-8026-4b29-bfb2-e889df6213c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - loss: 13.2255 - mae: 13.2255\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 7.7299 - mae: 7.7299\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 7.5289 - mae: 7.5289\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.9111 - mae: 7.9111\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.1767 - mae: 7.1767\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.2367 - mae: 7.2367\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.6849 - mae: 7.6849\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.4000 - mae: 6.4000\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.6611 - mae: 6.6611\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.8428 - mae: 6.8428\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.0793 - mae: 6.0793\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.3368 - mae: 5.3368\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.5091 - mae: 5.5091\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.9240 - mae: 4.9240\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.3075 - mae: 4.3075\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.4685 - mae: 4.4685\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.7821 - mae: 3.7821\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.2301 - mae: 3.2301\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.3411 - mae: 3.3411\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.2926 - mae: 2.2926\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.6085 - mae: 1.6085\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4159 - mae: 1.4159\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.8571 - mae: 0.8571\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3332 - mae: 1.3332\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.6962 - mae: 1.6962\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.5960 - mae: 1.5960\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2052 - mae: 1.2052\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.7116 - mae: 0.7116\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1852 - mae: 1.1852\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8968 - mae: 0.8968\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.7870 - mae: 0.7870\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0536 - mae: 1.0536\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.9169 - mae: 0.9169\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.7789 - mae: 0.7789\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0218 - mae: 1.0218\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6853 - mae: 0.6853\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8798 - mae: 0.8798\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0043 - mae: 1.0043\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5908 - mae: 0.5908\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6841 - mae: 0.6841\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5606 - mae: 0.5606\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1813 - mae: 0.1813\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1318 - mae: 1.1318\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1334 - mae: 1.1334\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5747 - mae: 0.5747\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.7502 - mae: 0.7502\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5005 - mae: 0.5005\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2873 - mae: 0.2873\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6179 - mae: 0.6179\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3396 - mae: 0.3396\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1576 - mae: 1.1576\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4280 - mae: 1.4280\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6948 - mae: 0.6948\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9432 - mae: 0.9432\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.2696 - mae: 1.2696\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7567 - mae: 0.7567\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.7936 - mae: 0.7936\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1230 - mae: 1.1230\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5258 - mae: 0.5258\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0095 - mae: 1.0095\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3278 - mae: 1.3278\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7643 - mae: 0.7643\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6820 - mae: 0.6820\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0378 - mae: 1.0378\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5049 - mae: 0.5049\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.8372 - mae: 0.8372\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0787 - mae: 1.0787\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5064 - mae: 0.5064\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.7891 - mae: 0.7891\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0139 - mae: 1.0139\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3711 - mae: 0.3711\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0275 - mae: 1.0275\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.4411 - mae: 1.4411\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0358 - mae: 1.0358\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2237 - mae: 0.2237\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5055 - mae: 0.5055\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0688 - mae: 0.0688\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6014 - mae: 0.6014\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.3698 - mae: 0.3698\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.6323 - mae: 0.6323\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7170 - mae: 0.7170\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0430 - mae: 0.0430\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1013 - mae: 0.1013\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3588 - mae: 0.3588\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0548 - mae: 0.0548\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2535 - mae: 0.2535\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3472 - mae: 0.3472\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1832 - mae: 0.1832\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6503 - mae: 0.6503\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5740 - mae: 0.5740\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3984 - mae: 0.3984\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5145 - mae: 0.5145\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2275 - mae: 0.2275\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0457 - mae: 0.0457\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6379 - mae: 0.6379\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5732 - mae: 0.5732\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2273 - mae: 0.2273\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1824 - mae: 0.1824\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5469 - mae: 0.5469\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5029 - mae: 0.5029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x308f07c80>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=None),\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# (1) in Dense means that we use one number as input and obtain one number as output\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,   # mae - means the mean absolute error\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01),\n",
    "              #optimizer = tf.keras.optimizers.SGD(),    # SGD - stochastic gradient descent\n",
    "              metrics = ['mae']\n",
    "             )\n",
    "\n",
    "# 3. Fit the model\n",
    "# Note that ndim must be 2, not 1, so we have to reshape the tensors\n",
    "X = tf.reshape(X, shape=(8, 1))\n",
    "Y = tf.reshape(Y, shape=(8, 1))\n",
    "X, Y\n",
    "\n",
    "model.fit(X, Y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a6eeec7f-cc4d-42f7-be55-8b2c8bd41a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[27.627085]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try and make a prediction using the model\n",
    "a = np.array([[17.0]]).astype('float32')\n",
    "model.predict(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1cb612-f819-4718-a08c-df39028a927b",
   "metadata": {},
   "source": [
    "We can improve the model by doing the following changes:\n",
    "\n",
    "In step 1. (creating the model):\n",
    "- we might add more layers\n",
    "- increase the number of hidden units (neurons) within each of the hidden layer\n",
    "- change the activation function of each layer\n",
    "In the step 2. (compiling the model):\n",
    "- we may change the optimization function\n",
    "- or the learning rate of the optimization function\n",
    "In the step 3. (fitting a model):\n",
    "- we may fit the model for more epochs (increasing the training time)\n",
    "- give the model more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbf9722-6fa1-4e4e-a438-30e6bb0e5f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
